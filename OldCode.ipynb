{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "\n",
        "# with zipfile.ZipFile('/content/sketchdata.zip', 'r') as ref:\n",
        "#   ref.extractall('/content/sketchdata')"
      ],
      "metadata": {
        "id": "qCjjNNLxKDIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4-pjzBlUJcYb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "import random\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the folder containing the images\n",
        "img_folder = '/content/photos/'\n",
        "\n",
        "# Get a list of all the image files in the folder\n",
        "image_files = [os.path.join(img_folder, f) for f in os.listdir(img_folder) if os.path.isfile(os.path.join(img_folder, f)) and f.endswith('.jpg')]\n",
        "\n",
        "# print(image_files)"
      ],
      "metadata": {
        "id": "IBRc1riN6VD-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "a1762151-9880-4863-db22-9d402ce18b63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-60708bc60077>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get a list of all the image files in the folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(image_files)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/photos/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the image files randomly\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Set the split ratio\n",
        "train_ratio = 0.7  # 70% of the images for training\n",
        "valid_ratio = 0.3  # 30% of the images for validation\n",
        "\n",
        "# Calculate the number of images for each set\n",
        "num_train = int(len(image_files) * train_ratio)\n",
        "num_valid = len(image_files) - num_train\n",
        "\n",
        "# Read the images into memory\n",
        "train_images = []\n",
        "train_labels = []\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "\n",
        "for i, image_file in enumerate(image_files):\n",
        "    # Load the image and convert it to grayscale\n",
        "    image = cv2.imread(image_file)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Split the filename to get the label\n",
        "    label = os.path.basename(image_file).split('-')[0]\n",
        "    \n",
        "    # Add the image and label to the appropriate set\n",
        "    if i < num_train:\n",
        "        train_images.append(image)\n",
        "        train_labels.append(label)\n",
        "    else:\n",
        "        valid_images.append(image)\n",
        "        valid_labels.append(label)\n",
        "\n",
        "# Convert the image and label lists to NumPy arrays\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "valid_images = np.array(valid_images)\n",
        "valid_labels = np.array(valid_labels)\n",
        "\n",
        "# Print some statistics\n",
        "print('Number of training images:', len(train_images))\n",
        "print('Number of validation images:', len(valid_images))\n",
        "print('Shape of a training image:', train_images[0].shape)\n"
      ],
      "metadata": {
        "id": "WWB2eMV0_R5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image and label lists to NumPy arrays\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "valid_images = np.array(valid_images)\n",
        "valid_labels = np.array(valid_labels)\n",
        "\n",
        "# Print some statistics\n",
        "# print('Number of training images:', len(train_images))\n",
        "# print('Number of validation images:', len(valid_images))\n",
        "# print('Shape of a training image:', train_images[0].shape)\n",
        "\n",
        "# Define hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.0002\n",
        "num_epochs = 50\n",
        "\n",
        "# Convert the image and label lists to PyTorch tensors\n",
        "train_images = torch.from_numpy(train_images).unsqueeze(1).float()\n",
        "train_labels = torch.from_numpy(train_labels).long()\n",
        "valid_images = torch.from_numpy(valid_images).unsqueeze(1).float()\n",
        "valid_labels = torch.from_numpy(valid_labels).long()\n",
        "\n",
        "# Create TensorDataset objects for the training and validation sets\n",
        "train_dataset = TensorDataset(train_images, train_labels)\n",
        "valid_dataset = TensorDataset(valid_images, valid_labels)\n",
        "\n",
        "# Create DataLoader objects for the training and validation sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "U4GHieopxfAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANLoss(nn.Module):\n",
        "        def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0):\n",
        "            super(GANLoss, self).__init__()\n",
        "            self.fake_label_var = None\n",
        "            self.real_label_var = None\n",
        "            self.real_label = target_real_label\n",
        "            self.fake_label = target_fake_label\n",
        "            self.Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "            if use_lsgan:\n",
        "                self.loss = nn.MSELoss()\n",
        "            else:\n",
        "                self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        def get_target_tensor(self, input_img, target_is_real):\n",
        "            target_tensor = None\n",
        "            if target_is_real:\n",
        "                create_label = ((self.real_label_var is None) or\n",
        "                                (self.real_label_var.numel() != input_img.numel()))\n",
        "                if create_label:\n",
        "                    real_tensor = self.Tensor(input_img.size()).fill_(self.real_label)\n",
        "                    self.real_label_var = nn.Parameter(real_tensor, requires_grad=False)\n",
        "                target_tensor = self.real_label_var\n",
        "            else:\n",
        "                create_label = ((self.fake_label_var is None) or\n",
        "                                (self.fake_label_var.numel() != input_img.numel()))\n",
        "                if create_label:\n",
        "                    fake_tensor = self.Tensor(input_img.size()).fill_(self.fake_label)\n",
        "                    self.fake_label_var = nn.Parameter(fake_tensor, requires_grad=False)\n",
        "                target_tensor = self.fake_label_var\n",
        "            return target_tensor\n",
        "\n",
        "        def forward(self, input_img, target_is_real):\n",
        "            target_tensor = self.get_target_tensor(input_img, target_is_real)\n",
        "            return self.loss(input_img, target_tensor.expand_as(input_img))"
      ],
      "metadata": {
        "id": "PsXjTo8xxi_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PerceptualLoss(nn.Module):\n",
        "        def __init__(self, layers, weights, cuda):\n",
        "            super(PerceptualLoss, self).__init__()\n",
        "            self.layers = layers\n",
        "            self.weights = weights\n",
        "            self.vgg = models.VGG19(pretrained=True).features\n",
        "            if cuda:\n",
        "                self.vgg = self.vgg.cuda()\n",
        "            for param in self.vgg.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        def forward(self, x, y):\n",
        "            x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
        "            loss = 0\n",
        "            for i, layer in enumerate(self.layers):\n",
        "                loss += self.weights[i] * F.l1_loss(x_vgg[layer], y_vgg[layer])\n",
        "            return loss"
      ],
      "metadata": {
        "id": "IBMK9WLNxm1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  class CycleConsistencyLoss(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(CycleConsistencyLoss, self).__init__()\n",
        "\n",
        "        def forward(self, x, y, x_recon, y_recon):\n",
        "            return F.l1_loss(x, x_recon) + F.l1_loss(y, y_recon)"
      ],
      "metadata": {
        "id": "jyf3J01JxpSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IdentityLoss(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(IdentityLoss, self).__init__()\n",
        "\n",
        "        def forward(self, x, y):\n",
        "            return F.l1_loss(x, y)"
      ],
      "metadata": {
        "id": "WHadW7B-xtsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchLoss(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(PatchLoss, self).__init__()\n",
        "            self.loss = nn.L1Loss()\n",
        "\n",
        "        def get_masked_images(self, input, gt, gtsegmap, label):\n",
        "            i, j = np.where(gtsegmap == label)\n",
        "            mask = torch.zeros_like(gtsegmap, dtype=torch.float32)\n",
        "            mask[i, j] = 1.0\n",
        "            input_m = input * mask.cuda()\n",
        "            gt_m = gt * mask.cuda()\n",
        "            return input_m, gt_m\n",
        "\n",
        "        def forward(self, input, gt, gtsegmap, label):\n",
        "            gtsegmap = (gtsegmap + 1) * 5.0\n",
        "            input_m, gt_m = self.get_masked_images(input, gt, gtsegmap, label)\n",
        "            gt_m = gt_m.detach()\n",
        "            return self.loss(input_m, gt_m)"
      ],
      "metadata": {
        "id": "KXaigbgwxwE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureMatchingLoss(nn.Module):\n",
        "        def __init__(self, device):\n",
        "            super(FeatureMatchingLoss, self).__init__()\n",
        "            self.vgg = VGGNet().to(device)\n",
        "            self.criterion = nn.L1Loss()\n",
        "\n",
        "        def forward(self, real_img, fake_img, D):\n",
        "            # Extract features from intermediate layers of the VGG network\n",
        "            real_features = self.vgg(real_img, D)\n",
        "            fake_features = self.vgg(fake_img, D)\n",
        "\n",
        "            # Calculate the L1 loss between the real and fake features\n",
        "            loss = 0\n",
        "            for i in range(len(real_features)):\n",
        "                loss += self.criterion(real_features[i], fake_features[i].detach())\n",
        "\n",
        "            return loss\n",
        "\n",
        "class VGGNet(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(VGGNet, self).__init__()\n",
        "            self.layer1 = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            self.layer2 = nn.Sequential(\n",
        "                nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            self.layer3 = nn.Sequential(\n",
        "                nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            self.layer4 = nn.Sequential(\n",
        "                nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            self.layer5 = nn.Sequential(\n",
        "                nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            self.layer6 = nn.Sequential(\n",
        "                nn.Linear(25088, 4096),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, 4096),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, 1000),\n",
        "                nn.ReLU())\n",
        "\n",
        "        def forward(self, x, D):\n",
        "            if D == 0:\n",
        "                x = self.layer1(x)\n",
        "                x = self.layer2(x)\n",
        "                x = self.layer3(x)\n",
        "                x = self.layer4(x)\n",
        "                x = self.layer5(x)\n",
        "            else:\n",
        "                for i in range(D):\n",
        "                    x = getattr(self, 'layer{}'.format(i + 1))(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.layer6(x)\n",
        "            return x"
      ],
      "metadata": {
        "id": "NTryWGtwxyu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform images to the same sizes\n",
        "# transform = transforms.Compose([transforms.RandomResizedCrop(size = (224, 224)),\n",
        "#                                 transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "5yo2hyjbftcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the images\n",
        "image_dir = '/content/sketchdata/photo'\n",
        "sketch_dir = '/content/sketchdata/original_sketch'\n",
        "\n",
        "images = []\n",
        "for file_name in os.listdir(image_dir):\n",
        "    if file_name.endswith('.png') or file_name.endswith('.jpg'):\n",
        "        image = Image.open(os.path.join(image_dir, file_name))\n",
        "        image = transform(image)\n",
        "        images.append(image)\n",
        "\n",
        "sketches = []\n",
        "for file_name in os.listdir(sketch_dir):\n",
        "    if file_name.endswith('.png') or file_name.endswith('.jpg'):\n",
        "        image = Image.open(os.path.join(sketch_dir, file_name))\n",
        "        image = transform(image)\n",
        "        sketches.append(image)\n",
        "\n",
        "images_tensor = torch.stack(images)\n",
        "sketches_tensor = torch.stack(sketches)"
      ],
      "metadata": {
        "id": "zjWzKouTe0bO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "3b8703fe-1aeb-453f-92d3-50281cef549f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e1e63852e893>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sketchdata/photo'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # load images in\n",
        "# class Data(Dataset):\n",
        "#   def __init__(self, x): #, y):\n",
        "#     self.x = x\n",
        "#     # self.y = y\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.x)\n",
        "  \n",
        "#   def __getitem__(self, index):\n",
        "#     # transform images to the same sizes\n",
        "#     transform = transforms.Compose([transforms.RandomResizedCrop(size = (224, 224)), transforms.ToTensor()])\n",
        "#     image = self.x[index]\n",
        "#     return transform(image)"
      ],
      "metadata": {
        "id": "uWeai4aaQHYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now load in eachdataset with the  dataloaders\n",
        "def load_data(images_tensor=images_tensor, sketches_tensor=sketches_tensor):\n",
        "  batch_size = 64\n",
        "  # images_transformed = Data(images_tensor)\n",
        "  # sketches_transformed = Data(sketches_tensor)\n",
        "  \n",
        "  images_loader = DataLoader(images_tensor, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "  sketches_loader = DataLoader(sketches_tensor, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "  return images_loader, sketches_loader"
      ],
      "metadata": {
        "id": "MfJwQ208fR1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images_loader[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "UtTjurfSpL-p",
        "outputId": "ad84d140-8bb4-400e-b1ee-2d769b44dea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c855bc8cecb5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the images\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "def imshow(img, title=None):\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def show_batch_images(dataloader, k=2):\n",
        "    images = next(iter(dataloader))\n",
        "    images = images[:k]\n",
        "    # labels = labels[:k]\n",
        "    img = make_grid(images) #, padding=25)\n",
        "    imshow(img) #, title=labels)\n",
        "\n",
        "images_loader, sketches_loader = load_data()\n",
        "for i in range(2):\n",
        "    show_batch_images(images_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "cphwYvnPgwIR",
        "outputId": "15342040-9932-4c50-fe0e-5194e9b87ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-5c12d11b09b9>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mimages_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msketches_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mshow_batch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-5c12d11b09b9>\u001b[0m in \u001b[0;36mshow_batch_images\u001b[0;34m(dataloader, k)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# labels = labels[:k]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, padding=25)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, title=labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mimages_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msketches_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-5c12d11b09b9>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(img, title)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0minterpolation_stage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         resample=None, url=None, data=None, **kwargs):\n\u001b[0;32m-> 2695\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   2696\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5663\u001b[0m                               **kwargs)\n\u001b[1;32m   5664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5665\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5666\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    708\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    709\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 710\u001b[0;31m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[1;32m    711\u001b[0m                             .format(self._A.shape))\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 228, 454) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def show_images(images, nmax=64):\n",
        "#     fig, ax = plt.subplots(figsize=(8, 8))\n",
        "#     ax.set_xticks([]); ax.set_yticks([])\n",
        "#     ax.imshow(make_grid((images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
        "# def show_batch(dl, nmax=64):\n",
        "#     for images in dl:\n",
        "#         show_images(images, nmax)\n",
        "#         break"
      ],
      "metadata": {
        "id": "UZXtRFcRgv9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# images_loader, sketches_loader = load_data()\n",
        "# show_batch(images_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "Qv01KgUdgvtm",
        "outputId": "9a51701a-1beb-4ff7-c697-6b0e6e0953f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = '/content/sketchdata/photo'\n",
        "sketch_dir = '/content/sketchdata/original_sketch'\n",
        "\n",
        "image_filenames = [name for name in os.listdir(image_dir) if os.path.splitext(name)[-1] == '.jpg']\n",
        "# image_files = np.load(dir)\n",
        "sketch_filenames = [name for name in os.listdir(sketch_dir) if os.path.splitext(name)[-1] == '.jpg']\n",
        "# sketch_files = np.load(dir)"
      ],
      "metadata": {
        "id": "NX0rm56JT7iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_tensor = torch.stack(image_filenames)\n",
        "sketch_tensor = torch.stack(sketch_filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "210eAW_Pctqg",
        "outputId": "152624ff-4eff-4af2-88f9-ee26ac2f1b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-98421cc679e6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msketch_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msketch_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got str"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b85WlyC9KTp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.first_stage = torch.nn.Conv2d(224, 224, 32)\n",
        "\n",
        "    self.second_stage = torch.nn.Conv2d(28, 28, 256)\n",
        "    self.third_stage = torch.nn.Conv2d(56, 56, 128)\n",
        "    self.fourth_stage = torch.nn.Conv2d(112, 112, 64)\n",
        "    one = torch.nn.Conv2d(1,1)\n",
        "    three = torch.nn.Conv2d(3,3)\n",
        "    m = torch.nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "\n",
        "\n",
        "  def forward(self, img):\n",
        "\n",
        "    feature_maps = []\n",
        "\n",
        "    output_img = torch.zeros(())\n",
        "\n",
        "    for i in range(1, N - 1):\n",
        "      f_m = feature_maps[i]\n",
        "      upsampled_fm = m(f_m)\n",
        "      f_m_1 = feature_maps[i + 1]\n",
        "      upsampled_fm = torch.cat((f_m, upsampled_fm))\n",
        "      ones_conv = one(upsampled_fm)\n",
        "      threes_conv = three(ones_conv)\n",
        "\n",
        "      feature_maps[i + 1] =  threes_conv\n",
        "\n",
        "\n",
        "    return feature_maps[-1]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rMZDWN7cJiRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    self.first_layer = torch.nn.Conv2d(3, 32, 3, stride = 2, padding = 1)\n",
        "    self.batch1 = torch.nn.BatchNorm2d(32, eps=1e-10)\n",
        "    self.second_layer = torch.nn.Conv2d(32, 32, 3, stride = 2, padding = 1)\n",
        "    self.batch2 = torch.nn.BatchNorm2d(32, eps=1e-10)\n",
        "    self.third_layer = torch.nn.Conv2d(32, 64, 3, stride = 2, padding = 1)\n",
        "    self.batch3 = torch.nn.BatchNorm2d(64, eps=1e-10)\n",
        "    self.fourth_layer = torch.nn.Conv2d(64, 64, 3, stride = 2, padding = 1)\n",
        "    self.batch4 = torch.nn.BatchNorm2d(64, eps=1e-10)\n",
        "    self.fifth_layer = torch.nn.Conv2d(64, 128, 3, stride = 2, padding = 1)\n",
        "    self.batch5 = torch.nn.BatchNorm2d(128, eps=1e-10)\n",
        "    self.sixth_layer = torch.nn.Conv2d(128, 1, 3, stride = 1, padding = 1)\n",
        "    self.batch6 = torch.nn.BatchNorm2d(1, eps=1e-10)\n",
        "    self.sigmoid = torch.nn.sigmoid()\n",
        "  \n",
        "  def forward(self, img):\n",
        "\n",
        "    first = F.relu(self.batch1(self.first_layer(img)))\n",
        "    second = F.relu(self.batch2(self.second_layer(first)))\n",
        "    third = F.relu(self.batch3(self.third_layer(second)))\n",
        "    fourth = F.relu(self.batch4(self.fourth_layer(third)))\n",
        "    fifth = F.relu(self.batch5(self.fifth_layer(fourth)))\n",
        "    sixth = F.relu(self.batch6(self.sixth_layer(fifth)))\n",
        "    output = self.sigmoid(sixth)\n",
        "\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "9ziLh2qChpz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KcNX9p-BNtJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rwxpi8WwCW3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}