{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse import triu\n",
    "from scipy.sparse import coo_matrix\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PYToolsSubset:\n",
    "    @staticmethod\n",
    "    # Reshape H x W x C matrix into HW x C\n",
    "    def VectorizeMatrix(mat):\n",
    "        vec = mat.reshape((mat.shape[0]*mat.shape[1], mat.shape[2]))\n",
    "        return vec\n",
    "        \n",
    "    @staticmethod\n",
    "    # Reshape HW x C matrix into H x W x C\n",
    "    def UnvectorizeMatrix(vec, rows, cols):\n",
    "        mat = vec.reshape((rows, cols, vec.shape[1]))\n",
    "        return mat\n",
    "        \n",
    "    @staticmethod\n",
    "    # Fast replacement of SUB2IND (Linear index from multiple subscripts)\n",
    "    # in dimension 2; no check is performed.\n",
    "    def Sub2ind_fast2(siz, i, j):\n",
    "        ind = i + (j-1)*siz[0]\n",
    "        return ind\n",
    "        \n",
    "    @staticmethod\n",
    "    # Fast replacement of SUB2IND (Linear index from multiple subscripts)\n",
    "    # in dimension 3; no check is performed.\n",
    "    def Sub2ind_fast3(siz, i, j, k):\n",
    "        ind = i + (j-1)*siz[0] + (k-1)*siz[0]*siz[1]\n",
    "        return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalTransfer:\n",
    "    def __init__(self, imgInput, imgMatch, imgTarget):\n",
    "        assert imgInput is not None, \"imgInput must not be empty\"\n",
    "\n",
    "        self.imgSize = imgInput.shape\n",
    "\n",
    "        # Vectorize all images\n",
    "        # self.imgInput_3R = np.reshape(imgInput, [-1, np.prod(self.imgSize)])\n",
    "        # self.imgMatch_3R = np.reshape(imgMatch, [-1, np.prod(self.imgSize)])\n",
    "        # self.imgTarget_3R = np.reshape(imgTarget, [-1, np.prod(self.imgSize)])\n",
    "        self.imgInput_3R = PYToolsSubset.VectorizeMatrix(imgInput)\n",
    "        self.imgMatch_3R = PYToolsSubset.VectorizeMatrix(imgMatch)\n",
    "        self.imgTarget_3R = PYToolsSubset.VectorizeMatrix(imgTarget)\n",
    "\n",
    "        self.linearIndicesInWindow_NP = None\n",
    "        self.sparseLinearIndices_pattern_row = None\n",
    "\n",
    "    @staticmethod\n",
    "    def fastApplyTransforms(imgInput, localTransform_array3CR):\n",
    "        C = localTransform_array3CR.shape[1]\n",
    "        R = localTransform_array3CR.shape[2]\n",
    "        assert (imgInput.shape[0] * imgInput.shape[1]) == R\n",
    "\n",
    "        imgInput_31R = np.reshape(np.transpose(np.reshape(imgInput, (R, 3))), (3, 1, R))\n",
    "        if C == 4:\n",
    "            imgInput_C1R = np.vstack((imgInput_31R, np.ones((1, 1, R))))\n",
    "        else:\n",
    "            imgInput_C1R = imgInput_31R\n",
    "\n",
    "        imgOutput_31R = localTransform_array3CR @ imgInput_C1R\n",
    "        imgOutput = np.transpose(np.reshape(np.transpose(imgOutput_31R), (3, R)), (1, 0)).reshape(imgInput.shape)\n",
    "\n",
    "        return imgOutput\n",
    "\n",
    "    @staticmethod\n",
    "    def ApplyPrecomputedTransform(imgInput, localTransform_array3CR, patchWidth):\n",
    "        if patchWidth == 1:\n",
    "            imgOutput = fastApplyTransforms(imgInput, localTransform_array3CR) \n",
    "        else:\n",
    "            localTransferRec = LocalTransfer_affineModel(imgInput, None, None)\n",
    "            localTransferRec.gatherSquarePatches(patchWidth)\n",
    "            \n",
    "            # If cached transform is diagonal or linear, extend it to affine\n",
    "            if localTransform_array3CR.shape[1] < 4:\n",
    "                localTransform_array3CR[:,3,:] = 0\n",
    "            \n",
    "            # Get the linear indices of the patch centers\n",
    "            patchCenters_linearIndex_1P = \\\n",
    "                localTransferRec.linearIndicesInWindow_NP[(patchWidth**2)//2,:]\n",
    "            \n",
    "            # Find the per-patch transform using the patch centers    \n",
    "            Ak_perPatch_34P = localTransform_array3CR[:,:,patchCenters_linearIndex_1P]\n",
    "            \n",
    "            # Apply the transforms on the input image\n",
    "            localTransferRec.estimateOutput_givenLocalTransforms(Ak_perPatch_34P)\n",
    "            \n",
    "            imgOutput = localTransferRec.imgOutput_3R.T.reshape(localTransferRec.imgSize)\n",
    "        \n",
    "        return imgOutput\n",
    "\n",
    "    @abstractmethod\n",
    "    def computeGlobalTransform(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def initializeLocalTransforms(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimateLocalTransforms_givenOutput(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def buildClosedFormMatrices(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def estimateInvBk_perPatch(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimateOutput_givenLocalTransforms(self):\n",
    "        pass\n",
    "\n",
    "    def computeError(self):\n",
    "        # IMPORTANT: This method assumes that the input and match images\n",
    "        # are identical. It computes the error between the transformed input\n",
    "        # (or transformed match) and the target image.\n",
    "\n",
    "        # Compute the per-pixel squared error\n",
    "        perPixelError_1R = np.sum((self.imgTarget_3R - self.imgOutput_3R) ** 2, axis=1)\n",
    "\n",
    "        perPixelError_1R = np.sqrt(perPixelError_1R)\n",
    "\n",
    "        # Sum the error over all pixels of every patch; store the error at the\n",
    "        # center pixel.\n",
    "        N = self.linearIndicesInWindow_NP.shape[0]\n",
    "        P = self.linearIndicesInWindow_NP.shape[1]\n",
    "        centerPixel_linearIndex_1P = self.linearIndicesInWindow_NP[math.ceil(N / 2) - 1, :]\n",
    "        perPixelError_NP = np.reshape(perPixelError_1R[self.linearIndicesInWindow_NP], (N, P))\n",
    "        perPatchError_1R = np.full_like(perPixelError_1R, np.nan)\n",
    "        perPatchError_1R[centerPixel_linearIndex_1P] = np.sum(perPixelError_NP, axis=0)\n",
    "\n",
    "        return perPixelError_1R, perPatchError_1R\n",
    "\n",
    "    def gatherSquarePatches(self, patchWidth):\n",
    "        halfK = patchWidth // 2\n",
    "        imageWidth = self.imgSize[1]\n",
    "        imageHeight = self.imgSize[0]\n",
    "\n",
    "        # Get the coordinate of the center pixel of all patches in the images,\n",
    "        # except near the borders\n",
    "        centerPixel_x = np.tile(np.arange(1 + halfK, imageWidth - halfK), (imageHeight - 2 * halfK, 1))\n",
    "        centerPixel_y = np.tile(np.arange(1 + halfK, imageHeight - halfK)[:, np.newaxis], (1, imageWidth - 2 * halfK))\n",
    "        # centerPixel_linearIndices = np.ravel_multi_index((centerPixel_y, centerPixel_x), (imageHeight, imageWidth))\n",
    "        centerPixel_linearIndices = PYToolsSubset.Sub2ind_fast2([imageHeight, imageWidth], centerPixel_y, centerPixel_x)\n",
    "\n",
    "        # Get the linear index offsets of all neighbors in a window\n",
    "        neighbors_offset_col = np.tile(np.arange(-halfK, halfK + 1), (patchWidth, 1))\n",
    "        neighbors_offset_row = neighbors_offset_col.T\n",
    "        neighbors_offset_linearIndices = neighbors_offset_col * imageHeight + neighbors_offset_row\n",
    "\n",
    "        # Get the linear index of each neighbor in each patch\n",
    "        N = neighbors_offset_linearIndices.size\n",
    "        patchesLinearIndices_NP = centerPixel_linearIndices.reshape(-1, 1) + neighbors_offset_linearIndices.ravel()\n",
    "\n",
    "        # Discard patches that contain at least one NaN pixel\n",
    "        badPatchIndices = findBadPatchIndices(self.imgInput_3R, patchesLinearIndices_NP)\n",
    "        if self.imgMatch_3R is not None:\n",
    "            badPatchIndices = np.concatenate((badPatchIndices, findBadPatchIndices(self.imgMatch_3R, patchesLinearIndices_NP)))\n",
    "        if self.imgTarget_3R is not None:\n",
    "            badPatchIndices = np.concatenate((badPatchIndices, findBadPatchIndices(self.imgTarget_3R, patchesLinearIndices_NP)))\n",
    "        patchesLinearIndices_NP = np.delete(patchesLinearIndices_NP, badPatchIndices, axis=1)\n",
    "\n",
    "        self.linearIndicesInWindow_NP = patchesLinearIndices_NP\n",
    "        self.sparseLinearIndices_pattern_row = np.tile(np.arange(N), (N, 1))  # used for computing neighborhoods in the adjacency matrices later\n",
    "\n",
    "\n",
    "    def findBadPatchIndices(img_3R, patchesLinearIndices_NP):\n",
    "        N, P = patchesLinearIndices_NP.shape\n",
    "\n",
    "        pixelValues_3NP = img_3R[:, patchesLinearIndices_NP.reshape(-1)]\n",
    "\n",
    "        nbNaNValuesPerPatch_1P = np.sum(np.isnan(pixelValues_3NP.reshape(3, N, P)), axis=0)\n",
    "\n",
    "        return np.nonzero(nbNaNValuesPerPatch_1P > 0)[0]\n",
    "\n",
    "    def perPixelLocalTransforms(self, Ak_perPatch_3CP):\n",
    "        N = self.linearIndicesInWindow_NP.shape[0]  # number of pixels per patch\n",
    "        R = self.imgInput_3R.shape[1]  # number of pixels in image\n",
    "        C = Ak_perPatch_3CP.shape[1]\n",
    "\n",
    "        # Create C images, where each pixel shows some part of the local\n",
    "        # transform estimated for the patch centered on this pixel\n",
    "        localTransform_array3CR = np.empty((3, C, R))\n",
    "        localTransform_array3CR[:] = np.nan\n",
    "        patchCenterLinearIndex_1P = self.linearIndicesInWindow_NP[N // 2, :]\n",
    "        localTransform_array3CR[:, :, patchCenterLinearIndex_1P] = Ak_perPatch_3CP\n",
    "\n",
    "        imgMask_HW = None\n",
    "        if (nargout > 1):  # FIND OUT nargout!!!!\n",
    "            isTransformNaN_1R = np.sum(np.isnan(localTransform_array3CR.reshape(3*C, R)), axis=0) > 0\n",
    "            imgMask_HW = np.reshape(~isTransformNaN_1R, self.imgSize)\n",
    "\n",
    "        return localTransform_array3CR, imgMask_HW\n",
    "\n",
    "    def perPixelTransformError(self, localTransform_array3CR):\n",
    "        N = self.linearIndicesInWindow_NP.shape[0]  # number of pixels per patch\n",
    "        P = self.linearIndicesInWindow_NP.shape[1]  # number of patches\n",
    "        R = self.imgInput_3R.shape[1]  # total number of pixels\n",
    "        C = localTransform_array3CR.shape[1]\n",
    "\n",
    "        # Gather matrix vk(M) and vk(T) for each patch\n",
    "        if C == 3:\n",
    "            M_CNP = np.reshape(self.imgMatch_3R[:, self.linearIndicesInWindow_NP.flatten()],\n",
    "                            (3, *self.linearIndicesInWindow_NP.shape))\n",
    "        elif C == 4:\n",
    "            M_CNP = np.reshape(self.imgMatch_4R[:, self.linearIndicesInWindow_NP.flatten()],\n",
    "                            (4, *self.linearIndicesInWindow_NP.shape))\n",
    "        T_3NP = np.reshape(self.imgTarget_3R[:, self.linearIndicesInWindow_NP.flatten()],\n",
    "                        (3, *self.linearIndicesInWindow_NP.shape))\n",
    "\n",
    "        # Get linear index of the center of each pixel\n",
    "        centerPixel_linearIndex_1P = self.linearIndicesInWindow_NP[np.ceil(N / 2).astype(int) - 1, :]\n",
    "        Ak_perPatch_3CP = localTransform_array3CR[:, :, centerPixel_linearIndex_1P]\n",
    "\n",
    "        # Apply the local transforms on each neighborhood\n",
    "        transformedM_3NP = np.matmul(Ak_perPatch_3CP, M_CNP)\n",
    "\n",
    "        # Sum the error over all pixels of every patch; store the error at the\n",
    "        # center pixel.\n",
    "        perTransformError_1P = np.sum(np.reshape((T_3NP - transformedM_3NP) ** 2, (-1, P)), axis=0)\n",
    "        perTransformError_1R = np.full((1, R), np.nan)\n",
    "        perTransformError_1R[:, centerPixel_linearIndex_1P] = perTransformError_1P\n",
    "\n",
    "        return perTransformError_1R\n",
    "\n",
    "    def transfer_closedForm(self):\n",
    "        # Parameters\n",
    "        epsilon = 1\n",
    "        gamma = 0.01\n",
    "\n",
    "        # Compute global transform, and globally transformed image\n",
    "        globalTransform_3C = self.computeGlobalTransform()\n",
    "\n",
    "        # Construct system matrix and right side\n",
    "        M_sparseRR, u_3R, invBk_perPatch_CCP = self.buildClosedFormMatrices(globalTransform_3C, epsilon, gamma)\n",
    "\n",
    "        # Make sure matrix M is symmetric\n",
    "        # (sometimes there are some inaccuracies, and M-M'=1e-14 in some cells)\n",
    "        # by replacing the lower triangle by the transpose of the upper triangle\n",
    "        M_sparseRR = triu(M_sparseRR) + triu(M_sparseRR, 1).transpose()\n",
    "\n",
    "        # Solve linear system\n",
    "        self.imgOutput_3R = np.linalg.solve(M_sparseRR, u_3R)\n",
    "\n",
    "        # Output transformed image\n",
    "        imgOutput = self.imgOutput_3R.transpose().reshape(self.imgSize)\n",
    "\n",
    "        # Estimate the best-matching local transforms\n",
    "        Ak_perPatch_3CP = self.estimateLocalTransforms_givenOutput(invBk_perPatch_CCP, globalTransform_3C, epsilon, gamma)\n",
    "\n",
    "        # Output the per-pixel local transform and corresponding binary mask\n",
    "        localTransform_array3CR, imgMask_HW = self.perPixelLocalTransforms(Ak_perPatch_3CP)\n",
    "\n",
    "        return imgOutput, localTransform_array3CR, imgMask_HW\n",
    "\n",
    "    def transfer_iterative(self, nbIterations):\n",
    "        # Parameters\n",
    "        epsilon = 1\n",
    "        gamma = 0.01\n",
    "\n",
    "        # Initialize lists that will contain per-iteration results\n",
    "        savePerIterationResults = (nargout > 3)\n",
    "        if savePerIterationResults:\n",
    "            imgOutput_perIteration = []\n",
    "            localTransform_array3CR_perIteration = []\n",
    "\n",
    "        # Compute global transform, and globally transformed image\n",
    "        globalTransform_3C = self.computeGlobalTransform()\n",
    "\n",
    "        # Precompute Bk^-1 for each patch\n",
    "        invBk_perPatch_CCP = self.estimateInvBk_perPatch(epsilon, gamma)\n",
    "\n",
    "        for it in range(1, nbIterations + 1):\n",
    "\n",
    "            if (it == 1):\n",
    "                # Initialize local transforms\n",
    "                Ak_perPatch_3CP = self.initializeLocalTransforms(\n",
    "                    globalTransform_3C, epsilon, gamma)\n",
    "            else:\n",
    "                # Re-estimate the local transforms, given the new output\n",
    "                Ak_perPatch_3CP = self.estimateLocalTransforms_givenOutput(\n",
    "                    invBk_perPatch_CCP, globalTransform_3C, epsilon, gamma)\n",
    "\n",
    "            # Apply transform on each patch to estimate the output image\n",
    "            self.estimateOutput_givenLocalTransforms(Ak_perPatch_3CP)\n",
    "\n",
    "            if (savePerIterationResults or (it == nbIterations)):\n",
    "\n",
    "                # Output transformed image\n",
    "                imgOutput = self.imgOutput_3R.T.reshape(self.imgSize)\n",
    "\n",
    "                # Output the per-pixel local transform and corresponding binary mask\n",
    "                localTransform_array3CR, imgMask_HW = self.perPixelLocalTransforms(\n",
    "                    Ak_perPatch_3CP)\n",
    "\n",
    "                # Also save the per-iteration results\n",
    "                if savePerIterationResults:\n",
    "                    imgOutput_perIteration.append(imgOutput)\n",
    "                    localTransform_array3CR_perIteration.append(localTransform_array3CR)\n",
    "\n",
    "        return (imgOutput, localTransform_array3CR, imgMask_HW, imgOutput_perIteration, localTransform_array3CR_perIteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalTransfer_affineModel(LocalTransfer):\n",
    "    def __init__(self, imgInput, imgMatch, imgTarget):\n",
    "        super().__init__(imgInput, imgMatch, imgTarget)\n",
    "\n",
    "        R = self.imgSize[0] * self.imgSize[1]\n",
    "        self.imgInput_4R = np.vstack((self.imgInput_3R, np.ones((1, R))))\n",
    "        self.imgMatch_4R = np.vstack((self.imgMatch_3R, np.ones((1, R))))\n",
    "        self.imgTarget_4R = np.vstack((self.imgTarget_3R, np.ones((1, R))))\n",
    "\n",
    "    def buildClosedFormMatrices(self, G_34, epsilon, gamma):\n",
    "        N = self.linearIndicesInWindow_NP.shape[0]  # number of pixels per patch\n",
    "        P = self.linearIndicesInWindow_NP.shape[1]  # number of patches\n",
    "        R = self.imgInput_3R.shape[1]  # total number of pixels\n",
    "\n",
    "        # Gather matrices vk_bar(I), vk_bar(M), vk(T), for each patch\n",
    "        Iban_4NP = self.imgInput_4R[:, self.linearIndicesInWindow_NP.flatten()].reshape(4, N, P)\n",
    "        Mar_4NP = self.imgMatch_4R[:, self.linearIndicesInWindow_NP.flatten()].reshape(4, N, P)\n",
    "        T_3NP = self.imgTarget_3R[:, self.linearIndicesInWindow_NP.flatten()].reshape(3, N, P)\n",
    "\n",
    "        # Compute inverse matrix Bk at each patch\n",
    "        invBk_perPatch_44P = self.estimateInvBk_perPatch(epsilon, gamma)\n",
    "        Bk_44P = np.linalg.inv(invBk_perPatch_44P)\n",
    "\n",
    "        # We obtain the matrix values for each patch by:\n",
    "        # sparseMatrix_vals_NN = eye(N) - Ibar' * Bk * Ibar;\n",
    "        Bk_Iban_4NP = np.matmul(Bk_44P, Iban_4NP)\n",
    "        Iban_t_Bk_Iban_NNP = np.matmul(Iban_4NP.transpose(0, 2, 1), Bk_Iban_4NP)\n",
    "        sparseMatrix_vals_NNP = np.eye(N) - Iban_t_Bk_Iban_NNP\n",
    "\n",
    "        # We obtain the right-side vector elements for each patch by:\n",
    "        # rightSide_vals_3N = (epsilon * T*Mbar' + gamma*G) * Bk * Ibar;\n",
    "        T_Mar_t_34P = np.matmul(T_3NP, Mar_4NP.transpose(0, 2, 1))\n",
    "        rightSide_vals_3NP = np.matmul((epsilon * T_Mar_t_34P + gamma * G_34), Bk_Iban_4NP)\n",
    "\n",
    "        # Store the sparse matrix triplets\n",
    "        sparseMatrix_rows_NNP = self.linearIndicesInWindow_NP[self.sparseLinearIndices_pattern_row, :, :]\n",
    "        sparseMatrix_cols_NNP = self.linearIndicesInWindow_NP[self.sparseLinearIndices_pattern_row[:, np.newaxis], :, :]\n",
    "        sparseMatrix_rows_NP = np.repeat(sparseMatrix_rows_NNP, N, axis=1)\n",
    "        sparseMatrix_cols_NP = np.tile(sparseMatrix_cols_NNP, (N, 1, 1))\n",
    "        sparseMatrix_vals_NP = sparseMatrix_vals_NNP.transpose(2, 0, 1).flatten()\n",
    "\n",
    "        # Assemble the final sparse matrix\n",
    "        M_sparseRR = coo_matrix((sparseMatrix_vals_NP, (sparseMatrix_rows_NP.flatten(), sparseMatrix_cols_NP.flatten())),\n",
    "                                shape=(R, R)).tocsr()\n",
    "\n",
    "        # Assemble the right side\n",
    "        # TODO: replace this with an accumarray\n",
    "        u_3R = np.zeros((3, R))\n",
    "        for k in range(P):\n",
    "            u_3R[:, self.linearIndicesInWindow_NP[:, k]] += rightSide_vals_3NP[:, :, k]\n",
    "\n",
    "        return M_sparseRR, u_3R, invBk_perPatch_44P\n",
    "\n",
    "    def computeGlobalTransform(self):\n",
    "        R = self.imgMatch_3R.shape[1]\n",
    "\n",
    "        nonNaNPixels = np.unique(self.linearIndicesInWindow_NP)\n",
    "        M_4R = self.imgMatch_4R[:, nonNaNPixels]\n",
    "        T_3R = self.imgTarget_3R[:, nonNaNPixels]\n",
    "\n",
    "        G_34 = np.dot(T_3R, np.linalg.pinv(M_4R))\n",
    "\n",
    "        if (nargout > 1):\n",
    "            imgTransformed_3R = np.dot(G_34, np.vstack([self.imgInput_3R, np.ones((1, R))]))\n",
    "            return (G_34, imgTransformed_3R)\n",
    "\n",
    "        return G_34\n",
    "\n",
    "    def estimateInvBk_perPatch(self, epsilon, gamma):\n",
    "        # Gather matrices vk_bar(I), vk_bar(M), vk(T), for each patch\n",
    "        Ibar_4NP = self.imgInput_4R[:, self.linearIndicesInWindow_NP].reshape((4, -1))\n",
    "        Mbar_4NP = self.imgMatch_4R[:, self.linearIndicesInWindow_NP].reshape((4, -1))\n",
    "\n",
    "        # We obtain (Bk)^-1 at each patch by vectorizing:\n",
    "        # invBk_44 = Ibar*Ibar' + epsilon*(Mbar*Mbar') + gamma*eye(4);\n",
    "        Ibar_Ibar_t_44P = np.dot(Ibar_4NP, Ibar_4NP.T)\n",
    "        Mbar_Mbar_t_44P = np.dot(Mbar_4NP, Mbar_4NP.T)\n",
    "        invBk_perPatch_44P = Ibar_Ibar_t_44P + epsilon * Mbar_Mbar_t_44P + gamma * np.eye(4)\n",
    "\n",
    "        return invBk_perPatch_44P\n",
    "\n",
    "    def estimateLocalTransforms_givenOutput(self, invBk_perPatch_44P, G_34, epsilon, gamma):\n",
    "        P = self.linearIndicesInWindow_NP.shape[1]  # number of patches\n",
    "\n",
    "        # Gather matrices vk_bar(I), vk_bar(M), vk(T), vk(O), for each patch\n",
    "        Ibar_4NP = self.imgInput_4R[:, self.linearIndicesInWindow_NP].reshape((4, -1))\n",
    "        Mbar_4NP = self.imgMatch_4R[:, self.linearIndicesInWindow_NP].reshape((4, -1))\n",
    "        T_3NP = self.imgTarget_3R[:, self.linearIndicesInWindow_NP].reshape((3, -1))\n",
    "        O_3NP = self.imgOutput_3R[:, self.linearIndicesInWindow_NP].reshape((3, -1))\n",
    "\n",
    "        # Compute inverse matrix Bk at each patch\n",
    "        Bk_44P = np.zeros_like(invBk_perPatch_44P)\n",
    "        for k in range(P):\n",
    "            Bk_44P[:, :, k] = np.linalg.inv(invBk_perPatch_44P[:, :, k])\n",
    "\n",
    "        # We obtain Ak at each patch by vectorizing:\n",
    "        # Ak_34 = (O*Ibar' + epsilon*T*Mbar' + gamma*G) * Bk;\n",
    "        O_Ibar_t_34P = np.dot(O_3NP, Ibar_4NP.T)\n",
    "        T_Mbar_t_34P = np.dot(T_3NP, Mbar_4NP.T)\n",
    "        leftSide_34P = gamma * G_34 + O_Ibar_t_34P + epsilon * T_Mbar_t_34P\n",
    "        Ak_perPatch_34P = np.dot(leftSide_34P, Bk_44P)\n",
    "\n",
    "        return Ak_perPatch_34P\n",
    "\n",
    "    def initializeLocalTransforms(self, G_34, epsilon, gamma):\n",
    "        P = self.linearIndicesInWindow_NP.shape[1]\n",
    "\n",
    "        # Gather matrices vk_bar(M), vk(T), for each patch\n",
    "        Mbar_4NP = self.imgMatch_4R[:, self.linearIndicesInWindow_NP].reshape((4, -1))\n",
    "        T_3NP = self.imgTarget_3R[:, self.linearIndicesInWindow_NP].reshape((3, -1))\n",
    "\n",
    "        # We obtain Ak at each patch by vectorizing:\n",
    "        # Ak_34 = (epsilon * (T*Mbar') + gamma*G) * ...\n",
    "        #   inv(epsilon * (Mbar*Mbar') + gamma*eye(4));\n",
    "        Mbar_Mbar_t_44P = np.dot(Mbar_4NP, Mbar_4NP.T)\n",
    "        T_Mbar_t_34P = np.dot(T_3NP, Mbar_4NP.T)\n",
    "        leftSide_34P = gamma * G_34 + epsilon * T_Mbar_t_34P\n",
    "        invRightSide_44P = gamma * np.eye(4) + epsilon * Mbar_Mbar_t_44P\n",
    "\n",
    "        # Inverse the right side for each patch\n",
    "        rightSide_44P = np.zeros_like(invRightSide_44P)\n",
    "        for k in range(P):\n",
    "            rightSide_44P[:, :, k] = np.linalg.inv(invRightSide_44P[:, :, k])\n",
    "\n",
    "        Ak_perPatch_34P = np.dot(leftSide_34P, rightSide_44P)\n",
    "\n",
    "        return Ak_perPatch_34P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\skimage\\transform\\_warps.py:160: RuntimeWarning: divide by zero encountered in divide\n",
      "  factors = np.divide(input_shape, output_shape)\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Owner\\Desktop\\FA2022\\CS445\\project\\CS445-Spring-2023-FinalProject\\SecondMethod\\Second.ipynb Cell 5\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/FA2022/CS445/project/CS445-Spring-2023-FinalProject/SecondMethod/Second.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m patch_width \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/FA2022/CS445/project/CS445-Spring-2023-FinalProject/SecondMethod/Second.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Load example input data and create synthetic match/target images\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/FA2022/CS445/project/CS445-Spring-2023-FinalProject/SecondMethod/Second.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m imgA \u001b[39m=\u001b[39m resize(plt\u001b[39m.\u001b[39;49mimread(\u001b[39m'\u001b[39;49m\u001b[39mimageA.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m), (\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m), scale_factor, anti_aliasing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/FA2022/CS445/project/CS445-Spring-2023-FinalProject/SecondMethod/Second.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m imgB \u001b[39m=\u001b[39m resize(plt\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mimageB.jpg\u001b[39m\u001b[39m'\u001b[39m), (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m), scale_factor, anti_aliasing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/FA2022/CS445/project/CS445-Spring-2023-FinalProject/SecondMethod/Second.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m imgA \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(imgA, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\skimage\\transform\\_warps.py:182\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39many((anti_aliasing_sigma \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m&\u001b[39m (factors \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    180\u001b[0m             warn(\u001b[39m\"\u001b[39m\u001b[39mAnti-aliasing standard deviation greater than zero but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m                  \u001b[39m\"\u001b[39m\u001b[39mnot down-sampling along all axes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 182\u001b[0m     image \u001b[39m=\u001b[39m ndi\u001b[39m.\u001b[39;49mgaussian_filter(image, anti_aliasing_sigma,\n\u001b[0;32m    183\u001b[0m                                 cval\u001b[39m=\u001b[39;49mcval, mode\u001b[39m=\u001b[39;49mndi_mode)\n\u001b[0;32m    185\u001b[0m zoom_factors \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m factors]\n\u001b[0;32m    186\u001b[0m out \u001b[39m=\u001b[39m ndi\u001b[39m.\u001b[39mzoom(image, zoom_factors, order\u001b[39m=\u001b[39morder, mode\u001b[39m=\u001b[39mndi_mode,\n\u001b[0;32m    187\u001b[0m                cval\u001b[39m=\u001b[39mcval, grid_mode\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\scipy\\ndimage\\_filters.py:368\u001b[0m, in \u001b[0;36mgaussian_filter\u001b[1;34m(input, sigma, order, output, mode, cval, truncate, radius)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(axes) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    367\u001b[0m     \u001b[39mfor\u001b[39;00m axis, sigma, order, mode, radius \u001b[39min\u001b[39;00m axes:\n\u001b[1;32m--> 368\u001b[0m         gaussian_filter1d(\u001b[39minput\u001b[39;49m, sigma, axis, order, output,\n\u001b[0;32m    369\u001b[0m                           mode, cval, truncate, radius\u001b[39m=\u001b[39;49mradius)\n\u001b[0;32m    370\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m output\n\u001b[0;32m    371\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\scipy\\ndimage\\_filters.py:269\u001b[0m, in \u001b[0;36mgaussian_filter1d\u001b[1;34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001b[0m\n\u001b[0;32m    267\u001b[0m sd \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(sigma)\n\u001b[0;32m    268\u001b[0m \u001b[39m# make the radius of the filter equal to truncate standard deviations\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m lw \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(truncate \u001b[39m*\u001b[39;49m sd \u001b[39m+\u001b[39;49m \u001b[39m0.5\u001b[39;49m)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m radius \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     lw \u001b[39m=\u001b[39m radius\n",
      "\u001b[1;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "# Set method parameters\n",
    "scale_factor = 0.5\n",
    "use_model = 'affine'\n",
    "use_closed_form = 1\n",
    "nb_iterations = 3\n",
    "patch_width = 5\n",
    "\n",
    "# Load example input data and create synthetic match/target images\n",
    "imgA = resize(plt.imread('imageA.jpg'), (0, 0), scale_factor, anti_aliasing=True)\n",
    "imgB = resize(plt.imread('imageB.jpg'), (0, 0), scale_factor, anti_aliasing=True)\n",
    "\n",
    "imgA = np.clip(imgA, 0, 1)\n",
    "imgB = np.clip(imgB, 0, 1)\n",
    "\n",
    "imgInput = imgA\n",
    "imgMatch = imgA\n",
    "\n",
    "imgTarget = np.multiply(imgA, np.reshape([0.9, 0.8, 0.7], (1, 1, 3)))\n",
    "imgTarget[:, :imgTarget.shape[1]//2, :] = -0.3 + np.multiply(imgTarget[:, :imgTarget.shape[1]//2, :], np.reshape([1.5, 1.3, 1], (1, 1, 3)))\n",
    "\n",
    "# Apply the color transfer\n",
    "if use_model == 'affine':\n",
    "    localTransfer = LocalTransfer_affineModel(imgInput, imgMatch, imgTarget)\n",
    "elif use_model == 'linear':\n",
    "    localTransfer = LocalTransfer_linearModel(imgInput, imgMatch, imgTarget)\n",
    "elif use_model == 'diagonal':\n",
    "    localTransfer = LocalTransfer_diagonalModel(imgInput, imgMatch, imgTarget)\n",
    "\n",
    "# Gather patches\n",
    "localTransfer.gatherSquarePatches(patch_width)\n",
    "\n",
    "# Apply transfer\n",
    "if use_closed_form:\n",
    "    imgOutput, localTransform_array3CR, imgMask_HW = localTransfer.transfer_closedForm()\n",
    "else:\n",
    "    imgOutput, localTransform_array3CR, imgMask_HW = localTransfer.transfer_iterative(nb_iterations)\n",
    "\n",
    "# Compute scaled error image\n",
    "imgDiff = 10 * np.abs(imgTarget - imgOutput)\n",
    "\n",
    "# Display the results\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10, 8))\n",
    "fig.suptitle('Input and results')\n",
    "axs[0, 0].imshow(imgMatch)\n",
    "axs[0, 0].set_title('Match image')\n",
    "axs[0, 1].imshow(imgInput)\n",
    "axs[0, 1].set_title('Input image')\n",
    "axs[0, 2].imshow(imgTarget)\n",
    "axs[0, 2].set_title('Target image')\n",
    "axs[1, 0].imshow(imgOutput)\n",
    "axs[1, 0].set_title('Output image with local transforms')\n",
    "axs[1, 1].imshow(imgDiff)\n",
    "axs[1, 1].set_title('Error')\n",
    "axs[1, 2].imshow(imgMask_HW)\n",
    "axs[1, 2].set_title('Mask')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
